{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books Factor Analysis\n",
    "The code below calculates additional factors from the dataset and tests their effectiveness in training with Logistic Regression and Random Forest\n",
    "\n",
    "Factors are:\n",
    "- ARI (Readability)\n",
    "- Review Length\n",
    "- punctuation\n",
    "- capitalisation\n",
    "- edit&update\n",
    "- adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#General Data/Plotting\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from tqdm.auto import tqdm \n",
    "import random\n",
    "\n",
    "# Language\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re \n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import textstat # pip install textstat\n",
    "\n",
    "# Modeling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import precision_score, recall_score , f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.layers import Dense , Embedding , Bidirectional , LSTM\n",
    "\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title.1</th>\n",
       "      <th>Review</th>\n",
       "      <th>helpful_0</th>\n",
       "      <th>helpful_1</th>\n",
       "      <th>ratio_percent</th>\n",
       "      <th>review_len</th>\n",
       "      <th>IsHelpful</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>36/37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Real Alaskan Sourdough</td>\n",
       "      <td>Ruth Allman has written an excellent book abou...</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>97</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>ruth allman written excellent book alaskan sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>29/30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True Alaskan cooking</td>\n",
       "      <td>I have been using this book since 1988, the ei...</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>i using book since eighth printing i honestly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>25/28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cheechako to Sourdough in 190 Pages</td>\n",
       "      <td>My poor dogeared, stained copy of this book ca...</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>my poor dogeared stained copy book came way da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eyewitness Travel Guide to Europe</td>\n",
       "      <td>3/20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Disappointed Romanian!</td>\n",
       "      <td>This book in my opinion is biased and takes an...</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>this book opinion biased take angle europe cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eyewitness Travel Guide to Europe</td>\n",
       "      <td>20/20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Going to Europe? Get this book!</td>\n",
       "      <td>If you're already a fan of the Eyewitness Trav...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>if youre already fan eyewitness travel guide s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title helpful  Rating  \\\n",
       "0                   Alaska Sourdough   36/37     5.0   \n",
       "1                   Alaska Sourdough   29/30     5.0   \n",
       "2                   Alaska Sourdough   25/28     5.0   \n",
       "3  Eyewitness Travel Guide to Europe    3/20     1.0   \n",
       "4  Eyewitness Travel Guide to Europe   20/20     5.0   \n",
       "\n",
       "                               Title.1  \\\n",
       "0               Real Alaskan Sourdough   \n",
       "1                 True Alaskan cooking   \n",
       "2  Cheechako to Sourdough in 190 Pages   \n",
       "3               Disappointed Romanian!   \n",
       "4      Going to Europe? Get this book!   \n",
       "\n",
       "                                              Review  helpful_0  helpful_1  \\\n",
       "0  Ruth Allman has written an excellent book abou...         36         37   \n",
       "1  I have been using this book since 1988, the ei...         29         30   \n",
       "2  My poor dogeared, stained copy of this book ca...         25         28   \n",
       "3  This book in my opinion is biased and takes an...          3         20   \n",
       "4  If you're already a fan of the Eyewitness Trav...         20         20   \n",
       "\n",
       "   ratio_percent  review_len  IsHelpful  \\\n",
       "0             97         153          1   \n",
       "1             96          63          1   \n",
       "2             89         206          1   \n",
       "3             15          92          0   \n",
       "4            100         234          1   \n",
       "\n",
       "                                     cleaned_reviews  \n",
       "0  ruth allman written excellent book alaskan sou...  \n",
       "1  i using book since eighth printing i honestly ...  \n",
       "2  my poor dogeared stained copy book came way da...  \n",
       "3  this book opinion biased take angle europe cle...  \n",
       "4  if youre already fan eyewitness travel guide s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Datasets/Modified_Books_rating.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title.1</th>\n",
       "      <th>Review</th>\n",
       "      <th>helpful_0</th>\n",
       "      <th>helpful_1</th>\n",
       "      <th>ratio_percent</th>\n",
       "      <th>review_len</th>\n",
       "      <th>IsHelpful</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>ARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>36/37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Real Alaskan Sourdough</td>\n",
       "      <td>Ruth Allman has written an excellent book abou...</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>97</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>ruth allman written excellent book alaskan sou...</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>29/30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True Alaskan cooking</td>\n",
       "      <td>I have been using this book since 1988, the ei...</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>i using book since eighth printing i honestly ...</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>25/28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cheechako to Sourdough in 190 Pages</td>\n",
       "      <td>My poor dogeared, stained copy of this book ca...</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>my poor dogeared stained copy book came way da...</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eyewitness Travel Guide to Europe</td>\n",
       "      <td>3/20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Disappointed Romanian!</td>\n",
       "      <td>This book in my opinion is biased and takes an...</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>this book opinion biased take angle europe cle...</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eyewitness Travel Guide to Europe</td>\n",
       "      <td>20/20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Going to Europe? Get this book!</td>\n",
       "      <td>If you're already a fan of the Eyewitness Trav...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>if youre already fan eyewitness travel guide s...</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title helpful  Rating  \\\n",
       "0                   Alaska Sourdough   36/37     5.0   \n",
       "1                   Alaska Sourdough   29/30     5.0   \n",
       "2                   Alaska Sourdough   25/28     5.0   \n",
       "3  Eyewitness Travel Guide to Europe    3/20     1.0   \n",
       "4  Eyewitness Travel Guide to Europe   20/20     5.0   \n",
       "\n",
       "                               Title.1  \\\n",
       "0               Real Alaskan Sourdough   \n",
       "1                 True Alaskan cooking   \n",
       "2  Cheechako to Sourdough in 190 Pages   \n",
       "3               Disappointed Romanian!   \n",
       "4      Going to Europe? Get this book!   \n",
       "\n",
       "                                              Review  helpful_0  helpful_1  \\\n",
       "0  Ruth Allman has written an excellent book abou...         36         37   \n",
       "1  I have been using this book since 1988, the ei...         29         30   \n",
       "2  My poor dogeared, stained copy of this book ca...         25         28   \n",
       "3  This book in my opinion is biased and takes an...          3         20   \n",
       "4  If you're already a fan of the Eyewitness Trav...         20         20   \n",
       "\n",
       "   ratio_percent  review_len  IsHelpful  \\\n",
       "0             97         153          1   \n",
       "1             96          63          1   \n",
       "2             89         206          1   \n",
       "3             15          92          0   \n",
       "4            100         234          1   \n",
       "\n",
       "                                     cleaned_reviews   ARI  \n",
       "0  ruth allman written excellent book alaskan sou...   8.1  \n",
       "1  i using book since eighth printing i honestly ...   5.7  \n",
       "2  my poor dogeared stained copy book came way da...   7.6  \n",
       "3  this book opinion biased take angle europe cle...  10.9  \n",
       "4  if youre already fan eyewitness travel guide s...  18.3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_ari(text):\n",
    "    ari = textstat.automated_readability_index(text)\n",
    "    return ari\n",
    "\n",
    "df['ARI'] = df['Review'].apply(calculate_ari)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reviews with ARI < 8: 41189\n"
     ]
    }
   ],
   "source": [
    "# number of reviews with an ARI < 8 (equals 3rd grade level and is very easy to read)\n",
    "low_ari_reviews = df[df['ARI'] < 8]\n",
    "num_low_ari_reviews = len(low_ari_reviews)\n",
    "\n",
    "print(f\"Number of Reviews with ARI < 8: {num_low_ari_reviews}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Title.1</th>\n",
       "      <th>Review</th>\n",
       "      <th>helpful_0</th>\n",
       "      <th>helpful_1</th>\n",
       "      <th>ratio_percent</th>\n",
       "      <th>review_len</th>\n",
       "      <th>IsHelpful</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>ARI</th>\n",
       "      <th>IsReadable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>36/37</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Real Alaskan Sourdough</td>\n",
       "      <td>Ruth Allman has written an excellent book abou...</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>97</td>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>ruth allman written excellent book alaskan sou...</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>29/30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True Alaskan cooking</td>\n",
       "      <td>I have been using this book since 1988, the ei...</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>i using book since eighth printing i honestly ...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska Sourdough</td>\n",
       "      <td>25/28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cheechako to Sourdough in 190 Pages</td>\n",
       "      <td>My poor dogeared, stained copy of this book ca...</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>my poor dogeared stained copy book came way da...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eyewitness Travel Guide to Europe</td>\n",
       "      <td>3/20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Disappointed Romanian!</td>\n",
       "      <td>This book in my opinion is biased and takes an...</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>this book opinion biased take angle europe cle...</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eyewitness Travel Guide to Europe</td>\n",
       "      <td>20/20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Going to Europe? Get this book!</td>\n",
       "      <td>If you're already a fan of the Eyewitness Trav...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>if youre already fan eyewitness travel guide s...</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title helpful  Rating  \\\n",
       "0                   Alaska Sourdough   36/37     5.0   \n",
       "1                   Alaska Sourdough   29/30     5.0   \n",
       "2                   Alaska Sourdough   25/28     5.0   \n",
       "3  Eyewitness Travel Guide to Europe    3/20     1.0   \n",
       "4  Eyewitness Travel Guide to Europe   20/20     5.0   \n",
       "\n",
       "                               Title.1  \\\n",
       "0               Real Alaskan Sourdough   \n",
       "1                 True Alaskan cooking   \n",
       "2  Cheechako to Sourdough in 190 Pages   \n",
       "3               Disappointed Romanian!   \n",
       "4      Going to Europe? Get this book!   \n",
       "\n",
       "                                              Review  helpful_0  helpful_1  \\\n",
       "0  Ruth Allman has written an excellent book abou...         36         37   \n",
       "1  I have been using this book since 1988, the ei...         29         30   \n",
       "2  My poor dogeared, stained copy of this book ca...         25         28   \n",
       "3  This book in my opinion is biased and takes an...          3         20   \n",
       "4  If you're already a fan of the Eyewitness Trav...         20         20   \n",
       "\n",
       "   ratio_percent  review_len  IsHelpful  \\\n",
       "0             97         153          1   \n",
       "1             96          63          1   \n",
       "2             89         206          1   \n",
       "3             15          92          0   \n",
       "4            100         234          1   \n",
       "\n",
       "                                     cleaned_reviews   ARI  IsReadable  \n",
       "0  ruth allman written excellent book alaskan sou...   8.1           0  \n",
       "1  i using book since eighth printing i honestly ...   5.7           1  \n",
       "2  my poor dogeared stained copy book came way da...   7.6           1  \n",
       "3  this book opinion biased take angle europe cle...  10.9           0  \n",
       "4  if youre already fan eyewitness travel guide s...  18.3           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_ari(df):\n",
    "    if df['ARI'] <= 8.0:\n",
    "        ari = 1 # for readable\n",
    "    else:\n",
    "        ari = 0 # for not readable\n",
    "    return ari\n",
    "\n",
    "df['IsReadable'] = df.apply(convert_ari, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_reviews', 'IsReadable']], df['IsHelpful'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Replace NaN with an empty string\n",
    "X_train['cleaned_reviews'].fillna('', inplace=True) \n",
    "\n",
    "# feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=6000) # ca 10% von Datensatz Phones\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['cleaned_reviews'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_reviews'])\n",
    "\n",
    "# Hinzufügen der 'IsReadable'-Spalte zu den TF-IDF-Matrizen\n",
    "X_train_final = pd.concat([pd.DataFrame(X_train_tfidf.toarray()), X_train['IsReadable'].reset_index(drop=True)], axis=1)\n",
    "X_test_final = pd.concat([pd.DataFrame(X_test_tfidf.toarray()), X_test['IsReadable'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_final.shape, X_test_final.shape\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_final.columns = X_train_final.columns.astype(str)\n",
    "X_test_final.columns = X_test_final.columns.astype(str)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_preds = lr_model.predict(X_test_final)\n",
    "rf_preds = rf_model.predict(X_test_final)\n",
    "\n",
    "# Evaluate models\n",
    "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_preds))\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training accuracy for both models\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_model.predict(X_train_final))\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_model.predict(X_train_final))\n",
    "\n",
    "# Plotting\n",
    "labels = ['Logistic Regression', 'Random Forest']\n",
    "train_accuracies = [lr_train_accuracy, rf_train_accuracy]\n",
    "test_accuracies = [lr_accuracy, rf_accuracy]\n",
    "\n",
    "ari_lr_train_accuracy = lr_train_accuracy\n",
    "ari_rf_train_accuracy = rf_train_accuracy\n",
    "\n",
    "ari_lr_test_accuracy = lr_accuracy\n",
    "ari_rf_test_accuracy = rf_accuracy\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy')\n",
    "rects2 = ax.bar(x + width/2, test_accuracies, width, label='Validation Accuracy')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('ARI: LR and RF Training and Validation Accuracy Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Annotating the bars with actual values\n",
    "def add_values(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2%}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_values(rects1)\n",
    "add_values(rects2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'cleaned_reviews'\n",
    "df = df.dropna(subset=['cleaned_reviews'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_reviews', 'review_len']], df['IsHelpful'], test_size=0.2, random_state=42)\n",
    "# feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=6000) # ca 10% von Datensatz Phones\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['cleaned_reviews'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_reviews'])\n",
    "\n",
    "# Hinzufügen der 'IsReadable'-Spalte zu den TF-IDF-Matrizen\n",
    "X_train_final = pd.concat([pd.DataFrame(X_train_tfidf.toarray()), X_train['review_len'].reset_index(drop=True)], axis=1)\n",
    "X_test_final = pd.concat([pd.DataFrame(X_test_tfidf.toarray()), X_test['review_len'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_final.shape, X_test_final.shape\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_final.columns = X_train_final.columns.astype(str)\n",
    "X_test_final.columns = X_test_final.columns.astype(str)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_preds = lr_model.predict(X_test_final)\n",
    "rf_preds = rf_model.predict(X_test_final)\n",
    "\n",
    "# Evaluate models\n",
    "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_preds))\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training accuracy for both models\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_model.predict(X_train_final))\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_model.predict(X_train_final))\n",
    "\n",
    "# Plotting\n",
    "labels = ['Logistic Regression', 'Random Forest']\n",
    "train_accuracies = [lr_train_accuracy, rf_train_accuracy]\n",
    "test_accuracies = [lr_accuracy, rf_accuracy]\n",
    "\n",
    "len_lr_train_accuracy = lr_train_accuracy\n",
    "len_rf_train_accuracy = rf_train_accuracy\n",
    "\n",
    "len_lr_test_accuracy = lr_accuracy\n",
    "len_rf_test_accuracy = rf_accuracy\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy')\n",
    "rects2 = ax.bar(x + width/2, test_accuracies, width, label='Validation Accuracy')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Review Length: LR and RF Training and Validation Accuracy Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Annotating the bars with actual values\n",
    "def add_values(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2%}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_values(rects1)\n",
    "add_values(rects2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Punctuation Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get punctuation ratio (! and ?)\n",
    "df['ExclamationMarks_Count'] = df['Review'].str.count('!')\n",
    "df['QuestionMarks_Count'] = df['Review'].str.count('\\?')\n",
    "\n",
    "# Calculate Ratio/Percent of Punc. Marks relative to review length\n",
    "df['ExclamationMarks_Ratio'] = df['ExclamationMarks_Count'] / df['review_len']\n",
    "df['QuestionMarks_Ratio'] = df['QuestionMarks_Count'] / df['review_len']\n",
    "\n",
    "df['ExclamationMarks_Ratio'] = df['ExclamationMarks_Ratio'].fillna(0)\n",
    "df['QuestionMarks_Ratio'] = df['QuestionMarks_Ratio'].fillna(0)\n",
    "\n",
    "df['ExclamationMarks_Percent'] = (df['ExclamationMarks_Ratio'] * 100).astype(int)\n",
    "df['QuestionMarks_Percent'] = (df['QuestionMarks_Ratio'] * 100).astype(int)\n",
    "\n",
    "# combine both\n",
    "df['Sum_punctuationMarks'] = df['ExclamationMarks_Percent'] + df['QuestionMarks_Percent']\n",
    "\n",
    "# delete unused columns:\n",
    "df.drop(['ExclamationMarks_Count', 'QuestionMarks_Count','ExclamationMarks_Ratio', 'QuestionMarks_Ratio','ExclamationMarks_Percent', 'QuestionMarks_Percent'], axis='columns', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_reviews', 'Sum_punctuationMarks']], df['IsHelpful'], test_size=0.2, random_state=42)\n",
    "# feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=6000) # ca 10% von Datensatz Phones\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['cleaned_reviews'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_reviews'])\n",
    "\n",
    "# Hinzufügen der 'IsReadable'-Spalte zu den TF-IDF-Matrizen\n",
    "X_train_final = pd.concat([pd.DataFrame(X_train_tfidf.toarray()), X_train['Sum_punctuationMarks'].reset_index(drop=True)], axis=1)\n",
    "X_test_final = pd.concat([pd.DataFrame(X_test_tfidf.toarray()), X_test['Sum_punctuationMarks'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_final.shape, X_test_final.shape\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_final.columns = X_train_final.columns.astype(str)\n",
    "X_test_final.columns = X_test_final.columns.astype(str)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_preds = lr_model.predict(X_test_final)\n",
    "rf_preds = rf_model.predict(X_test_final)\n",
    "\n",
    "# Evaluate models\n",
    "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_preds))\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training accuracy for both models\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_model.predict(X_train_final))\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_model.predict(X_train_final))\n",
    "\n",
    "# Plotting\n",
    "labels = ['Logistic Regression', 'Random Forest']\n",
    "train_accuracies = [lr_train_accuracy, rf_train_accuracy]\n",
    "test_accuracies = [lr_accuracy, rf_accuracy]\n",
    "\n",
    "pct_lr_train_accuracy = lr_train_accuracy\n",
    "pct_rf_train_accuracy = rf_train_accuracy\n",
    "\n",
    "pct_lr_test_accuracy = lr_accuracy\n",
    "pct_rf_test_accuracy = rf_accuracy\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy')\n",
    "rects2 = ax.bar(x + width/2, test_accuracies, width, label='Validation Accuracy')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Sum Punctuation Marks (? and !): LR and RF Training and Validation Accuracy Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Annotating the bars with actual values\n",
    "def add_values(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2%}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_values(rects1)\n",
    "add_values(rects2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capitalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Capslock_Count'] = df['Review'].str.findall(r'\\b(?![Ii]\\b)[A-Z]+\\b').str.len()\n",
    "df['Capslock_Ratio'] = df['Capslock_Count'] / df['review_len']\n",
    "df['Capslock_Ratio'] = df['Capslock_Ratio'].fillna(0)\n",
    "df['Capslock_Percent'] = (df['Capslock_Ratio'] * 100).astype(int)\n",
    "df.drop(['Capslock_Count','Capslock_Ratio'], axis='columns', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_reviews', 'Capslock_Percent']], df['IsHelpful'], test_size=0.2, random_state=42)\n",
    "# feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=6000) # ca 10% von Datensatz Phones\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['cleaned_reviews'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_reviews'])\n",
    "\n",
    "# Hinzufügen der 'IsReadable'-Spalte zu den TF-IDF-Matrizen\n",
    "X_train_final = pd.concat([pd.DataFrame(X_train_tfidf.toarray()), X_train['Capslock_Percent'].reset_index(drop=True)], axis=1)\n",
    "X_test_final = pd.concat([pd.DataFrame(X_test_tfidf.toarray()), X_test['Capslock_Percent'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_final.shape, X_test_final.shape\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_final.columns = X_train_final.columns.astype(str)\n",
    "X_test_final.columns = X_test_final.columns.astype(str)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_preds = lr_model.predict(X_test_final)\n",
    "rf_preds = rf_model.predict(X_test_final)\n",
    "\n",
    "# Evaluate models\n",
    "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_preds))\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training accuracy for both models\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_model.predict(X_train_final))\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_model.predict(X_train_final))\n",
    "\n",
    "# Plotting\n",
    "labels = ['Logistic Regression', 'Random Forest']\n",
    "train_accuracies = [lr_train_accuracy, rf_train_accuracy]\n",
    "test_accuracies = [lr_accuracy, rf_accuracy]\n",
    "\n",
    "cap_lr_test_accuracy = lr_accuracy\n",
    "cap_rf_test_accuracy = rf_accuracy\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy')\n",
    "rects2 = ax.bar(x + width/2, test_accuracies, width, label='Validation Accuracy')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Capslock: LR and RF Training and Validation Accuracy Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Annotating the bars with actual values\n",
    "def add_values(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2%}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_values(rects1)\n",
    "add_values(rects2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edits&Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contains_updates'] = df['Review'].str.contains('contains_updates', case=False).astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_reviews', 'contains_updates']], df['IsHelpful'], test_size=0.2, random_state=42)\n",
    "# feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=6000) # ca 10% von Datensatz Phones\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['cleaned_reviews'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_reviews'])\n",
    "\n",
    "# Hinzufügen der 'IsReadable'-Spalte zu den TF-IDF-Matrizen\n",
    "X_train_final = pd.concat([pd.DataFrame(X_train_tfidf.toarray()), X_train['contains_updates'].reset_index(drop=True)], axis=1)\n",
    "X_test_final = pd.concat([pd.DataFrame(X_test_tfidf.toarray()), X_test['contains_updates'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_final.shape, X_test_final.shape\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_final.columns = X_train_final.columns.astype(str)\n",
    "X_test_final.columns = X_test_final.columns.astype(str)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_preds = lr_model.predict(X_test_final)\n",
    "rf_preds = rf_model.predict(X_test_final)\n",
    "\n",
    "# Evaluate models\n",
    "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_preds))\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training accuracy for both models\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_model.predict(X_train_final))\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_model.predict(X_train_final))\n",
    "\n",
    "# Plotting\n",
    "labels = ['Logistic Regression', 'Random Forest']\n",
    "train_accuracies = [lr_train_accuracy, rf_train_accuracy]\n",
    "test_accuracies = [lr_accuracy, rf_accuracy]\n",
    "\n",
    "\n",
    "ed_lr_test_accuracy = lr_accuracy\n",
    "ed_rf_test_accuracy = rf_accuracy\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy')\n",
    "rects2 = ax.bar(x + width/2, test_accuracies, width, label='Validation Accuracy')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Edit/Update: LR and RF Training and Validation Accuracy Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Annotating the bars with actual values\n",
    "def add_values(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2%}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_values(rects1)\n",
    "add_values(rects2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in 'cleaned_reviews'\n",
    "df = df.dropna(subset=['cleaned_reviews'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_reviews', 'Rating']], df['IsHelpful'], test_size=0.2, random_state=42)\n",
    "# feature extraction\n",
    "vectorizer = TfidfVectorizer(max_features=6000) # ca 10% von Datensatz Phones\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['cleaned_reviews'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['cleaned_reviews'])\n",
    "\n",
    "# Hinzufügen der 'IsReadable'-Spalte zu den TF-IDF-Matrizen\n",
    "X_train_final = pd.concat([pd.DataFrame(X_train_tfidf.toarray()), X_train['Rating'].reset_index(drop=True)], axis=1)\n",
    "X_test_final = pd.concat([pd.DataFrame(X_test_tfidf.toarray()), X_test['Rating'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "X_train_final.shape, X_test_final.shape\n",
    "\n",
    "# Convert column names to strings\n",
    "X_train_final.columns = X_train_final.columns.astype(str)\n",
    "X_test_final.columns = X_test_final.columns.astype(str)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_preds = lr_model.predict(X_test_final)\n",
    "rf_preds = rf_model.predict(X_test_final)\n",
    "\n",
    "# Evaluate models\n",
    "lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, lr_preds))\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training accuracy for both models\n",
    "lr_train_accuracy = accuracy_score(y_train, lr_model.predict(X_train_final))\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_model.predict(X_train_final))\n",
    "\n",
    "# Plotting\n",
    "labels = ['Logistic Regression', 'Random Forest']\n",
    "train_accuracies = [lr_train_accuracy, rf_train_accuracy]\n",
    "test_accuracies = [lr_accuracy, rf_accuracy]\n",
    "\n",
    "rat_lr_train_accuracy = lr_train_accuracy\n",
    "rat_rf_train_accuracy = rf_train_accuracy\n",
    "\n",
    "rat_lr_test_accuracy = lr_accuracy\n",
    "rat_rf_test_accuracy = rf_accuracy\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, train_accuracies, width, label='Training Accuracy')\n",
    "rects2 = ax.bar(x + width/2, test_accuracies, width, label='Validation Accuracy')\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Rating: LR and RF Training and Validation Accuracy Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "# Annotating the bars with actual values\n",
    "def add_values(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2%}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_values(rects1)\n",
    "add_values(rects2)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for the groups\n",
    "labels = ['Logistic Regression Test Accuracy', 'Random Forest Test Accuracy']\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.15\n",
    "\n",
    "# Extract values for LR Test and RF Test\n",
    "len_values_subset = [len_lr_test_accuracy, len_rf_test_accuracy]\n",
    "ari_values_subset = [ari_lr_test_accuracy, ari_rf_test_accuracy]\n",
    "pct_values_subset = [pct_lr_test_accuracy, pct_rf_test_accuracy]\n",
    "cap_values_subset = [cap_lr_test_accuracy, cap_rf_test_accuracy]\n",
    "ed_values_subset = [ed_lr_test_accuracy, ed_rf_test_accuracy]\n",
    "rat_values_subset = [rat_lr_test_accuracy, rat_rf_test_accuracy]\n",
    "\n",
    "\n",
    "# Set the positions of bars on X-axis\n",
    "r1_subset = np.arange(len(labels))\n",
    "r2_subset = [x + bar_width for x in r1_subset]\n",
    "r3_subset = [x + bar_width for x in r2_subset]\n",
    "r4_subset = [x + bar_width for x in r3_subset]\n",
    "r5_subset = [x + bar_width for x in r4_subset]\n",
    "r6_subset = [x + bar_width for x in r5_subset]\n",
    "\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.bar(r1_subset, len_values_subset, color='blue', width=bar_width, edgecolor='grey', label='Review Length')\n",
    "ax.bar(r2_subset, ari_values_subset, color='orange', width=bar_width, edgecolor='grey', label='ARI')\n",
    "ax.bar(r3_subset, pct_values_subset, color='green', width=bar_width, edgecolor='grey', label='Punctuation')\n",
    "ax.bar(r4_subset, cap_values_subset, color='red', width=bar_width, edgecolor='grey', label='Capitalization')\n",
    "ax.bar(r5_subset, ed_values_subset, color='purple', width=bar_width, edgecolor='grey', label='Edit')\n",
    "ax.bar(r6_subset, ed_values_subset, color='purple', width=bar_width, edgecolor='grey', label='Rating')\n",
    "\n",
    "\n",
    "# Adding labels\n",
    "plt.xlabel('Accuracy Type', fontweight='bold')\n",
    "plt.ylabel('Accuracy Values', fontweight='bold')\n",
    "ax.set_xticks([r + 2*bar_width for r in range(len(labels))])\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "# Adding values above the bars\n",
    "for r, values in zip([r1_subset, r2_subset, r3_subset, r4_subset, r5_subset, r6_subset], [len_values_subset, ari_values_subset, pct_values_subset, cap_values_subset, ed_values_subset, rat_values_subset]):\n",
    "    for i, value in enumerate(values):\n",
    "        ax.text(r[i], value + 0.01, f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Set the y-axis limit between 0.6 and 0.7\n",
    "ax.set_ylim(0.74, 0.81)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
